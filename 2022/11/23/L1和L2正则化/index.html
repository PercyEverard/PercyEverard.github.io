<!-- build time:Mon Aug 07 2023 13:52:49 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="fengyepiaosa" href="https://percyeverard.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="fengyepiaosa" href="https://percyeverard.github.io/atom.xml"><link rel="alternate" type="application/json" title="fengyepiaosa" href="https://percyeverard.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="https://percyeverard.github.io/2022/11/23/L1%E5%92%8CL2%E6%AD%A3%E5%88%99%E5%8C%96/"><title>L1 和 L2 正则化 - 知识大陆 | Percy Feng = fengyepiaosa = Neuromancer</title><meta name="generator" content="Hexo 6.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">L1 和 L2 正则化</h1><div class="meta"><span class="item" title="创建时间：2022-11-23 19:21:44"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2022-11-23T19:21:44+08:00">2022-11-23</time></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Percy Feng</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><img src="https://s2.loli.net/2023/08/06/CqpbejH5U7KEyxi.jpg"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E7%9F%A5%E8%AF%86%E5%A4%A7%E9%99%86/" itemprop="item" rel="index" title="分类于 知识大陆"><span itemprop="name">知识大陆</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://percyeverard.github.io/2022/11/23/L1%E5%92%8CL2%E6%AD%A3%E5%88%99%E5%8C%96/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/magic.png"><meta itemprop="name" content="Percy Everard"><meta itemprop="description" content="Neuromancer, Really start to record my life, no longer lazy!"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="fengyepiaosa"></span><div class="body md" itemprop="articleBody"><p>了解什么是 L1 正则化和 L2 正则化，以及什么是正则化？</p><p><span id="more"></span></p><h1 id="l1正则化和l2正则化"><a class="anchor" href="#l1正则化和l2正则化">#</a> L1 正则化和 L2 正则化</h1><h2 id="1-正则化"><a class="anchor" href="#1-正则化">#</a> 1. 正则化</h2><h3 id="11-什么是正则化"><a class="anchor" href="#11-什么是正则化">#</a> 1.1 什么是正则化？</h3><p>Regularization，中文翻译过来可以称为正则化，或者叫做规范化。什么是规则？闭卷考试中不能查书，这就是规则，一个限制。同理，在这里，规则化（正则化）就是说给损失函数加上一些限制，通过这种规则去规范他们再接下来的循环迭代中，不要自我膨胀。</p><h3 id="12-正则化有什么用"><a class="anchor" href="#12-正则化有什么用">#</a> 1.2 正则化有什么用？</h3><p><img data-src="https://img-blog.csdnimg.cn/2020031610373195.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTk2MDg5MA==,size_16,color_FFFFFF,t_70" alt="回归模型的拟合程度"></p><p><img data-src="https://img-blog.csdnimg.cn/20200316112556508.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTk2MDg5MA==,size_16,color_FFFFFF,t_70" alt="分类模型的拟合程度"></p><p>可以看出，两张图的最后一个模型，都存在着过拟合的现象。</p><blockquote><p>解决过拟合的方案有：<br>清洗数据<br>减少模型参数，降低模型复杂度<br>增加惩罚因子（正则化），保留所有的特征，但是减少参数的大小（magnitude）</p></blockquote><p>可见，正则化就是解决模型过拟合的其中一个方法。</p><h3 id="13-正则化怎么用"><a class="anchor" href="#13-正则化怎么用">#</a> 1.3 正则化怎么用？</h3><p>机器学习中几乎都可以看到损失函数后面会添加一个额外项，常用的额外项一般有两种，一般英文称作 ℓ1 \ell_1ℓ 1-norm 和 ℓ2 \ell_2ℓ2​-norm，中文称作 L1 正则化 和 L2 正则化，或者 L1 范数 和 L2 范数。</p><p>L1 正则化和 L2 正则化可以看做是损失函数的惩罚项。所谓『惩罚』是指对损失函数中的某些参数做一些限制。<strong>对于线性回归模型，使用 L1 正则化的模型建叫做 Lasso 回归，使用 L2 正则化的模型叫做 Ridge 回归（岭回归）</strong>。下图是 Python 中 Lasso 回归的损失函数，式中加号后面一项 α ∣ ∣ w ∣ ∣ 1 \alpha||w||_1α∣∣w∣∣ 1 即为 L1 正则化项。</p><p><img data-src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwOTA0MTg0MjI4MTU4?x-oss-process=image/format,png#pic_center" alt="Lasso回归损失函数"></p><p>下图是 Python 中 Ridge 回归的损失函数，式中加号后面一项 α ∣ ∣ w ∣ ∣ 2 2 \alpha||w||_2^2α∣∣w∣∣22 即为 L2 正则化项。</p><p><img data-src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwOTA0MTg0MzE0MzMz?x-oss-process=image/format,png#pic_center" alt="岭回归损失函数"></p><p>一般回归分析中 w 表示特征的系数，从上式可以看到正则化项是对系数做了处理（限制）。L1 正则化和 L2 正则化的说明如下：</p><ul><li>L1 正则化是指权值向量 w 中各个元素的绝对值之和，通常表示为∣ ∣ w ∣ ∣ 1 ||w||_1∣∣w∣∣ 1<br>​- L2 正则化是指权值向量 w 中各个元素的平方和然后再求平方根（可以看到 Ridge 回归的 L2 正则化项有平方符号），通常表示为∣ ∣ w ∣ ∣ 2 ||w||_2∣∣w∣∣ 2​</li></ul><p>一般都会在正则化项之前添加一个系数，Python 的机器学习包 sklearn 中用 α 表示，一些文章也用 λ 表示。这个系数需要用户指定。</p><ul><li>L1 正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择</li><li>L2 正则化可以防止模型过拟合（overfitting）；一定程度上，L1 也可以防止过拟合</li></ul><h2 id="2-稀疏模型与特征选择的关系"><a class="anchor" href="#2-稀疏模型与特征选择的关系">#</a> 2. 稀疏模型与特征选择的关系</h2><blockquote><p>上面提到 L1 正则化有助于生成一个稀疏权值矩阵，进而可以用于特征选择。为什么要生成一个稀疏矩阵？</p></blockquote><p>稀疏矩阵指的是很多元素为 0，只有少数元素是非零值的矩阵，即得到的线性回归模型的大部分系数都是 0. 通常机器学习中特征数量很多，例如文本处理时，如果将一个词组（term）作为一个特征，那么特征数量会达到上万个（bigram）。在预测或分类时，那么多特征显然难以选择，但是如果代入这些特征得到的模型是一个稀疏模型，表示只有少数特征对这个模型有贡献，绝大部分特征是没有贡献的，或者贡献微小（因为它们前面的系数是 0 或者是很小的值，即使去掉对模型也没有什么影响），此时我们就可以只关注系数是非零值的特征。这就是稀疏模型与特征选择的关系。</p><h2 id="3-l1正则化"><a class="anchor" href="#3-l1正则化">#</a> 3. L1 正则化</h2><p>为什么 L1 正则化可以产生稀疏模型（L1 是怎么让系数等于零的）？</p><h3 id="正则化和特征选择的关系"><a class="anchor" href="#正则化和特征选择的关系">#</a> 正则化和特征选择的关系</h3><p>假设有如下带 L1 正则化的损失函数：<br>J = J 0 + α ∑ w ∣ w ∣ (1) J = J_0 + \alpha \sum_w{|w|} \tag{1}J=J0​+α w∑∣w∣(1)</p><p>其中 J 0 J_0J 0 是原始的损失函数，加号后面的一项是 L1 正则化项，α \alphaα 是正则化系数。注意到 L1 正则化是权值的绝对值之和，J JJ 是带有绝对值符号的函数，因此 J JJ 是不完全可微的。机器学习的任务就是要通过一些方法（比如梯度下降）求出损失函数的最小值。当我们在原始损失函数 J 0 J_0J 0​<br>后添加 L1 正则化项时，相当于对 J 0 J_0J<br>0​<br>做了一个约束。令 L = α ∑ w ∣ w ∣ L = \alpha \sum_w {|w|} L=α∑<br>w​<br>∣w∣，则 J = J 0 + L J = J_0 + LJ=J<br>0​<br>+L，此时我们的任务变成在 L LL 约束下求出 J 0 J_0J<br>0​<br>取最小值的解。考虑二维的情况，即只有两个权值 w 1 w^1w<br>1<br>和 w 2 w^2w<br>2<br>，此时 L = ∣ w 1 ∣ + ∣ w 2 ∣ L = |w<sup>1|+|w</sup>2|L=∣w<br>1<br>∣+∣w<br>2<br>∣。对于梯度下降法，求解 J 0 J_0J<br>0​<br>的过程可以画出等值线，同时 L1 正则化的函数 L LL 也可以在 w 1 w 2 w<sup>1w</sup>2w<br>1<br>w<br>2 的二维平面上画出来。如下图：</p><p><img data-src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwOTA0MTg0NDI4NDU5?x-oss-process=image/format,png#pic_center" alt="L1正则化"></p><p>图中等值线是 J 0 J_0J 0​<br>的等值线，黑色方形是 L LL 函数的图形。L = ∣ w 1 ∣ + ∣ w 2 ∣ L = |w<sup>1|+|w</sup>2|L=∣w<br>1<br>∣+∣w<br>2<br>∣，这个函数画出来就是一个方框（可以自己动手画一下）。<br>在图中，当 J 0 J_0J<br>0​<br>等值线与 L LL 图形首次相交的地方就是最优解。上图中 J 0 J_0J<br>0​<br>与 L LL 在 L LL 的一个顶点处相交，这个顶点就是最优解。注意到这个顶点的值是 (w 1 , w 2) = ( 0 , w ) (w^1, w^2) = (0, w)(w<br>1<br>,w<br>2<br>)=(0,w)。可以直观想象，因为 L LL 函数有很多『突出的角』（二维情况下四个，多维情况下更多），J 0 J_0J<br>0​<br>与这些角接触的机率会远大于与 L LL 其它部位接触的机率（这是很直觉的想象，突出的角比直线的边离等值线更近写），而在这些角上，会有很多权值等于 0（因为角就在坐标轴上），这就是为什么 L1 正则化可以产生稀疏模型，进而可以用于特征选择。</p><p>而正则化前面的系数 α \alphaα，可以控制 L LL 图形的大小。α \alphaα 越小，L LL 的图形越大（上图中的黑色方框）；α \alphaα 越大，L LL 的图形就越小，可以小到黑色方框只超出原点范围一点点，这是最优点的值 (w 1 , w 2) = ( 0 , w ) (w1,w2)=(0,w)(w1,w2)=(0,w) 中的 w ww 可以取到很小的值。</p><p>我觉得下面的博主讲的挺易懂的：<br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE0MjYwMTYvYXJ0aWNsZS9kZXRhaWxzLzExOTgzNjU5OA==">https://blog.csdn.net/u011426016/article/details/119836598</span></p><h2 id="4-l2正则化"><a class="anchor" href="#4-l2正则化">#</a> 4. L2 正则化</h2><p>假设有如下带 L2 正则化的损失函数：</p><p>J = J 0 + α ∑ w w 2 (2) J = J_0 + \alpha \sum_w<ruby>w<rp>(</rp><rt>2</rt><rp>)</rp></ruby>\tag{2}<br>J=J<br>0​<br>+α<br>w<br>∑​<br>w<br>2<br>(2)</p><p>同样可以画出他们在二维平面上的图形，如下：</p><p><img data-src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwOTA0MTg0NjQ2OTYz?x-oss-process=image/format,png#pic_center" alt="L2正则化"></p><p>二维平面下 L2 正则化的函数图形是个圆（绝对值的平方和，是个圆），与方形相比，被磨去了棱角。因此 J 0 J_0J<br>0​<br>与 L LL 相交时使得 w 1 w^1w<br>1<br>或 w 2 w^2w<br>2<br>等于零的机率小了许多（这个也是一个很直观的想象），这就是为什么 L2 正则化不具有稀疏性的原因，因为不太可能出现多数 w ww 都为 0 的情况。</p><h3 id="为什么梯度下降的等值线与正则化函数第一次交点是最优解"><a class="anchor" href="#为什么梯度下降的等值线与正则化函数第一次交点是最优解">#</a> 为什么梯度下降的等值线与正则化函数第一次交点是最优解？</h3><p>评论中有人问到过这个问题，这是带约束的最优化问题。这应该是在大一的高等数学就学到知识点，因为这里要用到拉格朗日乘子。如果有这样的问题，就需要复习一下高等数学了。这里有一个比较详细的数学讲解，可以参考：带约束的最优化问题。</p><p>如果还不清楚的话，可以参考博客：<br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnBpbmdfc2hpL2FydGljbGUvZGV0YWlscy81MjQzMzk3NQ==">https://blog.csdn.net/jinping_shi/article/details/52433975</span></p><h2 id="参考链接"><a class="anchor" href="#参考链接">#</a> 参考链接</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vemluZ3AvcC8xMDM3NTY5MS5odG1s">https://www.cnblogs.com/zingp/p/10375691.html</span></p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vc2t5ZnNtL3AvODQ1Njk2OC5odG1s">https://www.cnblogs.com/skyfsm/p/8456968.html</span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTIxNjI2MTMvYXJ0aWNsZS9kZXRhaWxzLzQ0MjYxNjU3P3NwbT0xMDAxLjIxMDEuMzAwMS42NjUwLjMmYW1wO3V0bV9tZWRpdW09ZGlzdHJpYnV0ZS5wY19yZWxldmFudC5ub25lLXRhc2stYmxvZy0yJTdFZGVmYXVsdCU3RUNUUkxJU1QlN0VSYXRlLTMtNDQyNjE2NTctYmxvZy0xMDQ4OTE1NjEucGNfcmVsZXZhbnRfbXVsdGlfcGxhdGZvcm1fd2hpdGVsaXN0djMmYW1wO2RlcHRoXzEtdXRtX3NvdXJjZT1kaXN0cmlidXRlLnBjX3JlbGV2YW50Lm5vbmUtdGFzay1ibG9nLTIlN0VkZWZhdWx0JTdFQ1RSTElTVCU3RVJhdGUtMy00NDI2MTY1Ny1ibG9nLTEwNDg5MTU2MS5wY19yZWxldmFudF9tdWx0aV9wbGF0Zm9ybV93aGl0ZWxpc3R2MyZhbXA7dXRtX3JlbGV2YW50X2luZGV4PTY=">https://blog.csdn.net/u012162613/article/details/44261657?spm=1001.2101.3001.6650.3&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-44261657-blog-104891561.pc_relevant_multi_platform_whitelistv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-44261657-blog-104891561.pc_relevant_multi_platform_whitelistv3&amp;utm_relevant_index=6</span></p><p><span class="exturl" data-url="aHR0cHM6Ly9zb25namlhbi5ibG9nLmNzZG4ubmV0L2FydGljbGUvZGV0YWlscy8xMDQ4OTE1NjE/c3BtPTEwMDEuMjEwMS4zMDAxLjY2NTAuMSZhbXA7dXRtX21lZGl1bT1kaXN0cmlidXRlLnBjX3JlbGV2YW50Lm5vbmUtdGFzay1ibG9nLTIlN0VkZWZhdWx0JTdFQ1RSTElTVCU3RVJhdGUtMS0xMDQ4OTE1NjEtYmxvZy03OTQyNTgzMS5wY19yZWxldmFudF9tdWx0aV9wbGF0Zm9ybV93aGl0ZWxpc3R2MyZhbXA7ZGVwdGhfMS11dG1fc291cmNlPWRpc3RyaWJ1dGUucGNfcmVsZXZhbnQubm9uZS10YXNrLWJsb2ctMiU3RWRlZmF1bHQlN0VDVFJMSVNUJTdFUmF0ZS0xLTEwNDg5MTU2MS1ibG9nLTc5NDI1ODMxLnBjX3JlbGV2YW50X211bHRpX3BsYXRmb3JtX3doaXRlbGlzdHYzJmFtcDt1dG1fcmVsZXZhbnRfaW5kZXg9Mg==">https://songjian.blog.csdn.net/article/details/104891561?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-104891561-blog-79425831.pc_relevant_multi_platform_whitelistv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-104891561-blog-79425831.pc_relevant_multi_platform_whitelistv3&amp;utm_relevant_index=2</span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhaW1hMTk5OC9hcnRpY2xlL2RldGFpbHMvNzk0MjU4MzE=">https://blog.csdn.net/haima1998/article/details/79425831</span></p></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2023-08-06 15:10:18" itemprop="dateModified" datetime="2023-08-06T15:10:18+08:00">2023-08-06</time></span></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>Percy Everard <i class="ic i-at"><em>@</em></i>fengyepiaosa</li><li class="link"><strong>本文链接：</strong> <a href="https://percyeverard.github.io/2022/11/23/L1%E5%92%8CL2%E6%AD%A3%E5%88%99%E5%8C%96/" title="L1 和 L2 正则化">https://percyeverard.github.io/2022/11/23/L1和L2正则化/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2022/11/23/%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2023&#x2F;08&#x2F;06&#x2F;zfA4ckxtN6KYX8T.jpg" title="特征缩放"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 知识大陆</span><h3>特征缩放</h3></a></div><div class="item right"><a href="/2022/11/23/%E5%9C%A8hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2023&#x2F;08&#x2F;06&#x2F;PNu8lIXhCfpw5qs.jpg" title="在hexo搭建博客遇到的问题"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 知识大陆</span><h3>在hexo搭建博客遇到的问题</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#l1%E6%AD%A3%E5%88%99%E5%8C%96%E5%92%8Cl2%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">1.</span> <span class="toc-text">L1 正则化和 L2 正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">1.1.</span> <span class="toc-text">1. 正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-%E4%BB%80%E4%B9%88%E6%98%AF%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 什么是正则化？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-%E6%AD%A3%E5%88%99%E5%8C%96%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 正则化有什么用？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-%E6%AD%A3%E5%88%99%E5%8C%96%E6%80%8E%E4%B9%88%E7%94%A8"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.3 正则化怎么用？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%A8%80%E7%96%8F%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.2.</span> <span class="toc-text">2. 稀疏模型与特征选择的关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-l1%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">1.3.</span> <span class="toc-text">3. L1 正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E5%92%8C%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.3.1.</span> <span class="toc-text">正则化和特征选择的关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-l2%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">1.4.</span> <span class="toc-text">4. L2 正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9A%84%E7%AD%89%E5%80%BC%E7%BA%BF%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96%E5%87%BD%E6%95%B0%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BA%A4%E7%82%B9%E6%98%AF%E6%9C%80%E4%BC%98%E8%A7%A3"><span class="toc-number">1.4.1.</span> <span class="toc-text">为什么梯度下降的等值线与正则化函数第一次交点是最优解？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5"><span class="toc-number">1.5.</span> <span class="toc-text">参考链接</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2022/11/20/github%E6%96%87%E4%BB%B6%E5%A4%B9%E6%9C%89%E7%99%BD%E8%89%B2%E7%AE%AD%E5%A4%B4%E5%B9%B6%E4%B8%94%E4%B8%8D%E8%83%BD%E6%89%93%E5%BC%80%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/" rel="bookmark" title="github文件夹有白色箭头并且不能打开的解决办法">github文件夹有白色箭头并且不能打开的解决办法</a></li><li><a href="/2022/11/23/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B%E6%89%87%E5%BD%A2%E4%B8%8E%E7%9F%A9%E5%BD%A2%E5%9B%BE%E5%83%8F%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2/" rel="bookmark" title="图像处理之扇形与矩形图像之间的相互转换">图像处理之扇形与矩形图像之间的相互转换</a></li><li><a href="/2022/11/23/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" rel="bookmark" title="激活函数">激活函数</a></li><li><a href="/2022/11/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E9%AA%8C%E4%BA%8C/" rel="bookmark" title="机器学习实验二">机器学习实验二</a></li><li><a href="/2022/11/23/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/" rel="bookmark" title="维度灾难">维度灾难</a></li><li><a href="/2022/11/23/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="bookmark" title="特征工程">特征工程</a></li><li><a href="/2022/11/23/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/" rel="bookmark" title="交叉验证">交叉验证</a></li><li><a href="/2022/11/23/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E8%A1%A5%E5%85%85/" rel="bookmark" title="交叉验证补充">交叉验证补充</a></li><li><a href="/2022/11/23/Jupyter-Notebook/" rel="bookmark" title="Jupyter Notebook">Jupyter Notebook</a></li><li><a href="/2022/11/23/%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE/" rel="bookmark" title="特征缩放">特征缩放</a></li><li class="active"><a href="/2022/11/23/L1%E5%92%8CL2%E6%AD%A3%E5%88%99%E5%8C%96/" rel="bookmark" title="L1和L2正则化">L1和L2正则化</a></li><li><a href="/2022/11/23/%E5%9C%A8hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/" rel="bookmark" title="在hexo搭建博客遇到的问题">在hexo搭建博客遇到的问题</a></li><li><a href="/2022/11/23/%E6%8F%92%E5%85%A5YouTube%E8%A7%86%E9%A2%91/" rel="bookmark" title="插入YouTube视频">插入YouTube视频</a></li><li><a href="/2022/11/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B4%BE%E7%B3%BB/" rel="bookmark" title="机器学习派系">机器学习派系</a></li><li><a href="/2022/11/24/%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2/" rel="bookmark" title="网格搜索">网格搜索</a></li><li><a href="/2022/11/24/pip%E5%AE%89%E8%A3%85%E6%96%B0%E5%BA%93/" rel="bookmark" title="pip安装新库">pip安装新库</a></li><li><a href="/2022/11/24/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E5%AD%A6%E4%B9%A0%E4%B8%80/" rel="bookmark" title="卷积神经网络CNN学习一">卷积神经网络CNN学习一</a></li><li><a href="/2022/11/24/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E4%B9%8BCNN%E5%88%86%E7%B1%BB/" rel="bookmark" title="猫狗大战之CNN分类">猫狗大战之CNN分类</a></li><li><a href="/2022/12/11/docker%E6%89%93%E5%BC%80%E6%8A%A5%E9%94%99/" rel="bookmark" title="docker打开报错">docker打开报错</a></li><li><a href="/2022/12/13/%E5%85%B3%E4%BA%8E%E9%82%A3%E4%BA%9B%E6%88%91%E4%B8%80%E7%9B%B4%E6%90%9E%E4%B8%8D%E6%87%82%E7%9A%84%E5%B8%82%E5%88%B6%E5%8D%95%E4%BD%8D/" rel="bookmark" title="关于那些我一直搞不懂的市制单位">关于那些我一直搞不懂的市制单位</a></li><li><a href="/2023/01/13/TPU%E5%92%8CGPU%E7%9A%84%E4%B8%8D%E5%90%8C%E4%B9%8B%E5%A4%84/" rel="bookmark" title="The difference between GPU AND TPU">The difference between GPU AND TPU</a></li><li><a href="/2023/03/10/Ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85Git/" rel="bookmark" title="Ubuntu下安装Git">Ubuntu下安装Git</a></li><li><a href="/2023/03/11/%E5%88%86%E6%9E%90%E5%BC%80%E6%BA%90MusicPlayer%E7%9A%84%E4%B8%80%E4%BA%9B%E6%94%B6%E8%8E%B7/" rel="bookmark" title="分析开源MusicPlayer的一些收获">分析开源MusicPlayer的一些收获</a></li><li><a href="/2023/03/12/Qt-class-FAQ/" rel="bookmark" title="Qt class FAQ">Qt class FAQ</a></li><li><a href="/2023/03/12/Ubuntu-practise-C-inward/" rel="bookmark" title="Ubuntu practise C++ inward">Ubuntu practise C++ inward</a></li><li><a href="/2023/03/13/%E7%94%A8Qt-Designer%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E5%BA%94%E7%94%A8%E7%9A%84%E6%AD%A5%E9%AA%A4/" rel="bookmark" title="用Qt-Designer设计一个应用的步骤">用Qt-Designer设计一个应用的步骤</a></li><li><a href="/2023/03/13/Qt-Designer%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/" rel="bookmark" title="Qt-Designer常见操作">Qt-Designer常见操作</a></li><li><a href="/2023/03/22/Qt%E6%8E%A7%E4%BB%B6%E5%AD%A6%E4%B9%A02/" rel="bookmark" title="Qt控件学习2">Qt控件学习2</a></li><li><a href="/2023/03/23/libGL/" rel="bookmark" title="Linux环境下Qt报错libGL">Linux环境下Qt报错libGL</a></li><li><a href="/2023/03/28/Qt%E6%8E%A7%E4%BB%B6%E5%AD%A6%E4%B9%A03/" rel="bookmark" title="Qt控件学习3">Qt控件学习3</a></li><li><a href="/2023/04/05/obsidian%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7-%E5%90%AB%E9%93%BE%E6%8E%A5/" rel="bookmark" title="obsidian双向链接">obsidian双向链接</a></li><li><a href="/2023/04/23/xlog-%E5%9B%BE%E5%BA%8A/" rel="bookmark" title="xlog/图床">xlog/图床</a></li><li><a href="/2023/04/30/Linux-%E4%B8%AD%E7%9A%84-32-%E4%BD%8D%E4%B8%8E-64-%E4%BD%8D%E5%8C%BA%E5%88%AB/" rel="bookmark" title="Linux中32位与64位区别">Linux中32位与64位区别</a></li><li><a href="/2023/05/22/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" rel="bookmark" title="视频理解的基础知识">视频理解的基础知识</a></li><li><a href="/2023/07/20/Linux%E7%B3%BB%E7%BB%9F%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/" rel="bookmark" title="Linux系统目录结构">Linux系统目录结构</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Percy Everard" data-src="/images/magic.png"><p class="name" itemprop="name">Percy Everard</p><div class="description" itemprop="description">Really start to record my life, no longer lazy!</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">69</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">7</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">54</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3BlcmN5ZXZlcmFyZA==" title="https:&#x2F;&#x2F;github.com&#x2F;percyeverard"><i class="ic i-github"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvbXkvbS9tdXNpYy9wbGF5bGlzdD9pZD0yMjk0OTY3NTIy" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;my&#x2F;m&#x2F;music&#x2F;playlist?id&#x3D;2294967522"><i class="ic i-cloud-music"></i></span> <span class="exturl item email" data-url="bWFpbHRvOmZlbmd5ZXBpYW9zYUAxNjMuY29t" title="mailto:fengyepiaosa@163.com"><i class="ic i-envelope"></i></span> <span class="exturl item instagram" data-url="aHR0cHM6Ly9pbnN0YWdyYW0uY29tL2NoYXJsZXNmZW5n" title="https:&#x2F;&#x2F;instagram.com&#x2F;charlesfeng"><i class="ic i-instagram"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2022/11/23/%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2022/11/23/%E5%9C%A8hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"></div><div class="status"><div class="copyright">&copy; 2021 – <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="ic i-wenfeng"></i> </span><span class="author" itemprop="copyrightHolder">Percy Everard @ Percy Feng</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">156k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">2:21</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2022/11/23/L1和L2正则化/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->