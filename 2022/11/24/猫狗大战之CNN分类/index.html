<!-- build time:Mon Aug 07 2023 12:04:13 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="fengyepiaosa" href="https://percyeverard.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="fengyepiaosa" href="https://percyeverard.github.io/atom.xml"><link rel="alternate" type="application/json" title="fengyepiaosa" href="https://percyeverard.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="deep learning,cnn,match,image classification"><link rel="canonical" href="https://percyeverard.github.io/2022/11/24/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E4%B9%8BCNN%E5%88%86%E7%B1%BB/"><title>猫狗大战之 CNN 分类 - 知识大陆 | Percy Feng = fengyepiaosa = Neuromancer</title><meta name="generator" content="Hexo 6.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">猫狗大战之 CNN 分类</h1><div class="meta"><span class="item" title="创建时间：2022-11-24 19:24:47"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2022-11-24T19:24:47+08:00">2022-11-24</time></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Percy Feng</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><img src="https://s2.loli.net/2023/08/06/ezoGUtT4A6m3uBj.jpg"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E7%9F%A5%E8%AF%86%E5%A4%A7%E9%99%86/" itemprop="item" rel="index" title="分类于 知识大陆"><span itemprop="name">知识大陆</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://percyeverard.github.io/2022/11/24/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E4%B9%8BCNN%E5%88%86%E7%B1%BB/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/magic.png"><meta itemprop="name" content="Percy Everard"><meta itemprop="description" content="Neuromancer, Really start to record my life, no longer lazy!"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="fengyepiaosa"></span><div class="body md" itemprop="articleBody"><p>实践出真知！在 kaggle 上找的 CNN 经典案例练练手，猫狗大战属于图像分类问题。可以从此处下载所需要用到的数据<span class="exturl" data-url="aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS9kYXRhc2V0cy90b25ncHl0aG9uL2NhdC1hbmQtZG9n"> Here!</span></p><p><span id="more"></span></p><h1 id="import-required-libraries-dependencies"><a class="anchor" href="#import-required-libraries-dependencies">#</a> Import required libraries / dependencies</h1><p><pre><code>import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt

import keras
import tensorflow as tf
from keras.models import Sequential
from keras import layers
from tensorflow.keras.optimizers import Adam</code></pre></p><p><strong>tf.keras</strong> 是用于构建和训练深度学习模型的 TensorFlow 高阶 API。它和 TensorFlow 相比具有以下的优点：</p><ol><li>对错误实现精确反馈，方便用户使用</li><li>将可配置的构造块组合在一起便能构建 Keras 模型，模块化</li><li>得益于上一点，我们可以编写自定义构造块，表达新的研究创意，即易于拓展</li></ol><p>而对于 <code>from keras.models import Sequential</code> ，在 Keras 中有两种深度学习的模型，分别是序列模型（Sequential）和通用模型（Model），两者的差异在于它们之间允许的不同的拓扑结构。详细地可以参考<span class="exturl" data-url="aHR0cHM6Ly9rZXJhcy5pby9tb2RlbHMvc2VxdWVudGlhbC8="> Keras 官方文档</span>，这里我就简单讲解一下。Sequential 模型结构是一种简单的线性结构，是多个网络层的堆叠（这说的网络层指的是卷积层、池化层等）。而 Model 模型结构是非线性的，允许多输入多输出的模型。利用 Model 模型我们设计非常复杂、任意拓扑的神经网络，可以说用法更灵活，但难度明显更大。</p><p><code>from keras import layers</code> 允许我们使用各种各样的网络结构，是组成完整模型的零件。</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Nzc3dpbGwvYXJ0aWNsZS9kZXRhaWxzLzg4MzEwODEy">CSDN-keras-layers:Dense,Embedding,LSTM</span></li><li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dpbnRlcl9weXRob24vYXJ0aWNsZS9kZXRhaWxzLzEwODYxMjYzNg==">CSDN-keras.layers 汇总</span></li></ul><p><code>from tensorflow.keras.optimizers import Adam</code> 这是一个名叫 Adam 的优化器，在监督学习中我们使用梯度下降算法的时候，学习率是一个很重要的指标。Adam 能够让学习率从大到小自适应，实现效率与效果的兼得。</p><blockquote><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0lfY2Fuam51L2FydGljbGUvZGV0YWlscy8xMDYwMzU2NDA=">CSDN - 机器学习之优化器 keras.optimizers.Adam () 详解</span></p></blockquote><h1 id="generate-the-datasets-both-the-training-and-the-test-sets"><a class="anchor" href="#generate-the-datasets-both-the-training-and-the-test-sets">#</a> Generate the datasets, both the training and the test sets</h1><h2 id="define-the-paths-to-the-dataset"><a class="anchor" href="#define-the-paths-to-the-dataset">#</a> define the paths to the dataset.</h2><p><pre><code>training_path &#x3D; &#39;..&#x2F;input&#x2F;cat-and-dog&#x2F;training_set&#x2F;training_set&#x2F;&#39;
test_path &#x3D; &#39;..&#x2F;input&#x2F;cat-and-dog&#x2F;test_set&#x2F;test_set&#x2F;&#39;</code></pre></p><h2 id="create-dataset"><a class="anchor" href="#create-dataset">#</a> Create dataset</h2><p><pre><code>image_size &#x3D; (200, 200)
batch_size &#x3D; 32

training_set &#x3D; keras.preprocessing.image.image_dataset_from_directory(
    directory&#x3D;training_path,
    class_names&#x3D;[&#39;cats&#39;, &#39;dogs&#39;],
    image_size&#x3D;image_size,
    batch_size&#x3D;batch_size
)
test_set &#x3D; keras.preprocessing.image.image_dataset_from_directory(
    directory&#x3D;test_path,
    class_names&#x3D;[&#39;cats&#39;, &#39;dogs&#39;],
    image_size&#x3D;image_size,
    batch_size&#x3D;batch_size,
    
)</code></pre></p><p>keras.preprocessing.image.image_dataset_from_directory 可以理解成数据预处理工具包，TensorFlow 的官方文档在<span class="exturl" data-url="aHR0cHM6Ly90ZW5zb3JmbG93Lmdvb2dsZS5jbi9hcGlfZG9jcy9weXRob24vdGYva2VyYXMvdXRpbHMvaW1hZ2VfZGF0YXNldF9mcm9tX2RpcmVjdG9yeQ==">此</span>。它能够从文件夹里对子目录猫和狗分别生成标签 0 和 1，将数据返回到 tf.data.Dateset 中，并且在加载的同时还会打乱数据。</p><h1 id="visualize-some-images-from-the-training-set"><a class="anchor" href="#visualize-some-images-from-the-training-set">#</a> Visualize some images from the training set</h1><h2 id="visualize-the-training-set"><a class="anchor" href="#visualize-the-training-set">#</a> visualize the training set</h2><p><pre><code>plt.figure(figsize&#x3D;(15, 9))
def cat_or_dog(a):
    if a&#x3D;&#x3D;0:
        return &#39;Cat&#39;
    return &#39;Dog&#39;
    
for images, labels in training_set.take(1):
    for i in range(12):
        plt.subplot(3, 4, i+1)
        plt.imshow(images[i].numpy().astype(&#39;uint8&#39;))
        plt.title(f&#39;{int(labels[i])} ({cat_or_dog(int(labels[i]))})&#39;)
        plt.axis(&#39;off&#39;)</code></pre></p><h2 id="visualize-the-test-set"><a class="anchor" href="#visualize-the-test-set">#</a> visualize the test set</h2><p><pre><code>plt.figure(figsize&#x3D;(15, 9))
def cat_or_dog(a):
    if a&#x3D;&#x3D;0:
        return &#39;Cat&#39;
    return &#39;Dog&#39;
    
for images, labels in test_set.take(1):
    for i in range(12):
        plt.subplot(3, 4, i+1)
        plt.imshow(images[i].numpy().astype(&#39;uint8&#39;))
        plt.title(f&#39;{int(labels[i])} ({cat_or_dog(int(labels[i]))})&#39;)
        plt.axis(&#39;off&#39;)</code></pre></p><p>要是对 <code>plt.figure(figsize = (a, b))</code> 和 <code>plt.subplot()</code> 不懂的话，可以看看<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzY4NTg0NC9hcnRpY2xlL2RldGFpbHMvODg5ODI4MTE=">这里</span>。而这里的 <code>dataset.take(1)</code> 指的是取构建 dataset 的第一组元素，看样子一组好像有 12 个（因为下面的 circle）, 并且可以返回图片 image 和标签 label 两个值。</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNTY5Ni9hcnRpY2xlL2RldGFpbHMvMTEyNjkxNzU1">CSDN-dataset.take</span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC85NWYxMTY0OGJlMmM=">简书 - dataset.take</span></li></ul><h1 id="data-augmentation"><a class="anchor" href="#data-augmentation">#</a> Data Augmentation</h1><blockquote><p>augmentation /ˌɔːɡmenˈteɪʃ(ə) n/ 增大，增多；增加物；延长，扩充</p></blockquote><h2 id="define-some-layers-of-data-augmentation"><a class="anchor" href="#define-some-layers-of-data-augmentation">#</a> define some layers of data augmentation</h2><p><pre><code>augmented_data &#x3D; Sequential([
    layers.RandomFlip(&#39;horizontal&#39;),
    layers.RandomRotation(0.1)
])</code></pre></p><h2 id="visualize-it"><a class="anchor" href="#visualize-it">#</a> visualize it</h2><p><pre><code>plt.figure(figsize&#x3D;(15, 9))
    
for images, labels in test_set.take(1):
    for i in range(12):
        plt.subplot(3, 4, i+1)
        augmented_image &#x3D; augmented_data(images[0])
        plt.imshow(augmented_image.numpy().astype(&#39;uint8&#39;))
        plt.title(int(labels[0]))
        plt.axis(&#39;off&#39;)</code></pre></p><p><strong>tf.keras.layers.RandomFlip</strong> 的作用是一个预处理层，在训练期间随机翻转图像<span class="exturl" data-url="aHR0cHM6Ly9ydW5lYm9vay5kZXYvemgtQ04vZG9jcy90ZW5zb3JmbG93L2tlcmFzL2xheWVycy9yYW5kb21mbGlw"> runebook</span>、<span class="exturl" data-url="aHR0cHM6Ly9rZXJhcy5pby9hcGkvbGF5ZXJzL3ByZXByb2Nlc3NpbmdfbGF5ZXJzL2ltYWdlX3ByZXByb2Nlc3NpbmcvcmFuZG9tX2ZsaXAv">官方文档</span></p><h1 id="build-a-model"><a class="anchor" href="#build-a-model">#</a> Build a model</h1><h2 id="build-the-model"><a class="anchor" href="#build-the-model">#</a> build the model</h2><p><pre><code>model &#x3D; Sequential([
    layers.Conv2D(filters&#x3D;128, kernel_size&#x3D;(3, 3), activation&#x3D;&#39;relu&#39;, padding&#x3D;&#39;same&#39;, input_shape&#x3D;(200, 200, 3)),
    
    # preprocessing
    layers.CenterCrop(180, 180),
    layers.Rescaling(scale&#x3D;1.&#x2F;255),
    
    
    # applying image data augmentation
    layers.RandomFlip(&#39;horizontal&#39;),
    layers.RandomRotation(0.1),
    
    layers.MaxPooling2D(pool_size&#x3D;(2, 2), strides&#x3D;2),
    
    layers.Conv2D(filters&#x3D;256, kernel_size&#x3D;(3, 3), activation&#x3D;&#39;relu&#39;, padding&#x3D;&#39;same&#39;),
    layers.MaxPooling2D(pool_size&#x3D;(2, 2), strides&#x3D;2),
    
    layers.Conv2D(filters&#x3D;64, kernel_size&#x3D;(3, 3), activation&#x3D;&#39;relu&#39;, padding&#x3D;&#39;same&#39;),
    layers.MaxPooling2D(pool_size&#x3D;(2, 2), strides&#x3D;2),
    
    layers.Conv2D(filters&#x3D;32, kernel_size&#x3D;(3, 3), activation&#x3D;&#39;relu&#39;, padding&#x3D;&#39;same&#39;),
    layers.MaxPooling2D(pool_size&#x3D;(2, 2), strides&#x3D;2),
    
    layers.Flatten(),
    
    # output layer
    layers.Dense(1, activation&#x3D;&#39;sigmoid&#39;)
])</code></pre></p><p>tf.keras.layers.Conv2D 的 filter 为什么是 128 呢？这一点让我很疑惑。查阅资料发现许多都讲得模棱两可，不过大概可以解释的是这个 filter 指的是过滤器的深度。我没有查阅官方文档，后来发现<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80OTg3MTMwNjA=">知乎 - tf.keras.layers.Conv2D 参数详解</span>中的分析比较可取。&quot;我几乎总是建议使用 2 的次方作为值&quot; 说明 2 的次方并不是 filter 的专利，并且我们需要根据数据集的复杂性和神经网络的深度来调整确切的值，也就是说 filter 的选择主观性强。</p><ol><li><span class="exturl" data-url="aHR0cHM6Ly9ydW5lYm9vay5kZXYvemgtQ04vZG9jcy90ZW5zb3JmbG93L2tlcmFzL2xheWVycy9jZW50ZXJjcm9w">tf.keras.layers.CenterCropCrop</span> 对图片进行裁切，去两边留中心。官方解释 --&gt;<em>the central portion of the images to target height and width</em></li><li><span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnczY3ViLmNvbS90ZW5zb3JmbG93fjIuOS9rZXJhcy9sYXllcnMvcmVzY2FsaW5nLmh0bWw=">tf.keras.layers.Rescaling</span>To rescale an input in the [0, 255] range to be in the [0, 1] range, you would pass scale=1./255</li><li>Dense 层 (全连接层）</li><li>Flatten 层用来将输入 “压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。Flatten 不影响 batch 的大小。据说 Convolution 卷积层之后是无法直接连接 Dense 全连接层的，需要把 Convolution 层的数据压平（Flatten），然后才可以直接加 Dense 层。</li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vcGVuZzgwOTgvcC9rZXJhc183Lmh0bWwjOn46dGV4dD0lMjBGbGF0dGVuJUU1JUIxJTgyJUU3JTk0JUE4JUU2JTlEJUE1JUU1JUIwJTg2JUU4JUJFJTkzJUU1JTg1JUE1JUUyJTgwJTlDJUU1JThFJThCJUU1JUI5JUIzJUUyJTgwJTlEJUVGJUJDJThDJUU1JThEJUIzJUU2JThBJThBJUU1JUE0JTlBJUU3JUJCJUI0JUU3JTlBJTg0JUU4JUJFJTkzJUU1JTg1JUE1JUU0JUI4JTgwJUU3JUJCJUI0JUU1JThDJTk2JUVGJUJDJThDJUU1JUI4JUI4JUU3JTk0JUE4JUU1JTlDJUE4JUU0JUJCJThFJUU1JThEJUI3JUU3JUE3JUFGJUU1JUIxJTgyJUU1JTg4JUIwJUU1JTg1JUE4JUU4JUJGJTlFJUU2JThFJUE1JUU1JUIxJTgyJUU3JTlBJTg0JUU4JUJGJTg3JUU2JUI4JUExJUUzJTgwJTgyJTIwRmxhdHRlbiVFNCVCOCU4RCVFNSVCRCVCMSVFNSU5MyU4RGJhdGNoJUU3JTlBJTg0JUU1JUE0JUE3JUU1JUIwJThGJUUzJTgwJTgyLCVFOCVCRSU5MyVFNSU4NSVBNXNoYXBlJUVGJUJDJTlBJUU0JUJCJUJCJUU2JTg0JThGJUVGJUJDJThDJUU0JUJEJTg2JUU4JUJFJTkzJUU1JTg1JUE1JUU3JTlBJTg0c2hhcGUlRTUlQkYlODUlRTklQTElQkIlRTUlOUIlQkElRTUlQUUlOUElRTMlODAlODIlMjAlRTUlQkQlOTMlRTQlQkQlQkYlRTclOTQlQTglRTglQUYlQTUlRTUlQjElODIlRTQlQjglQkElRTYlQTglQTElRTUlOUUlOEIlRTklQTYlOTYlRTUlQjElODIlRTYlOTclQjYlRUYlQkMlOEMlRTklOUMlODAlRTglQTYlODElRTYlOEMlODclRTUlQUUlOUFpbnB1dF9zaGFwZSVFNSU4RiU4MiVFNiU5NSVCMCUyMFBlcm11dGUlRTUlQjElODIlRTUlQjAlODYlRTglQkUlOTMlRTUlODUlQTUlRTclOUElODQlRTclQkIlQjQlRTUlQkElQTYlRTYlOEMlODklRTclODUlQTclRTclQkIlOTklRTUlQUUlOUElRTYlQTglQTElRTUlQkMlOEYlRTglQkYlOUIlRTglQTElOEMlRTklODclOEQlRTYlOEUlOTIlRUYlQkMlOEMlRTQlQkUlOEIlRTUlQTYlODIlRUYlQkMlOEMlRTUlQkQlOTMlRTklOUMlODAlRTglQTYlODElRTUlQjAlODZSTk4lRTUlOTIlOENDTk4lRTclQkQlOTElRTclQkIlOUMlRTglQkYlOUUlRTYlOEUlQTUlRTYlOTclQjYlRUYlQkMlOEMlRTUlOEYlQUYlRTglODMlQkQlRTQlQkMlOUElRTclOTQlQTglRTUlODglQjAlRTglQUYlQTUlRTUlQjElODIlRTMlODAlODI=">cnblog 对 Keras.layers 各种层的介绍 - 比较准确</span></li></ol><h2 id="model-summary"><a class="anchor" href="#model-summary">#</a> model summary</h2><p><pre><code>model.summary()</code></pre></p><p>使用 keras 构建深度学习模型，我们会通过 model.summary () 输出模型各层的参数状况。通过这些参数，可以看到模型各个层的组成（dense 表示全连接层）。也能看到数据经过每个层后，输出的数据维度。还能看到 Param，它表示每个层参数的个数，详情参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3liZGVzaXJlL2FydGljbGUvZGV0YWlscy84NTIxNzY4OA==">此处</span>。这一步是先将模型搭建起来，然后用 summary 查看相关的信息，不属于训练过程，所以运行不需要花多少时间。</p><h1 id="train-the-model"><a class="anchor" href="#train-the-model">#</a> Train the model</h1><p><pre><code>epochs &#x3D; 50
# callbacks (save the model at each epoch)
callbacks &#x3D; [
    keras.callbacks.ModelCheckpoint(&quot;checkpoints&#x2F;model_at_{epoch}.h5&quot;),
]</code></pre></p><p><strong>tf.keras.callbacks.ModelCheckpoint</strong> 回调函数的作用是在每个训练期（epoch）后保存模型 --&gt;<span class="exturl" data-url="aHR0cHM6Ly93d3cudzNjc2Nob29sLmNuL3RlbnNvcmZsb3dfcHl0aG9uL3RmX2tlcmFzX2NhbGxiYWNrc19Nb2RlbENoZWNrcG9pbnQuaHRtbA==">Reference</span></p><p><pre><code># compile the model
model.compile(
    optimizer&#x3D;Adam(learning_rate&#x3D;0.001),
    loss&#x3D;&#39;binary_crossentropy&#39;,
    metrics&#x3D;[&#39;accuracy&#39;]
)</code></pre></p><p>Keras 的 model.compile 参数介绍：</p><p><pre><code>model.compile(
   optimizer, 
   loss &#x3D; None, 
   metrics &#x3D; None, 
   loss_weights &#x3D; None, 
   sample_weight_mode &#x3D; None, 
   weighted_metrics &#x3D; None, 
   target_tensors &#x3D; None
)</code></pre></p><p>常用的就下面三个参数：</p><ol><li>optimizer：优化器，用于控制梯度裁剪</li><li>loss：损失函数（或称目标函数、优化评分函数）</li><li>metrics：评价函数用于评估当前训练模型的性能。当模型编译后（compile），评价函数应该作为 metrics 的参数来输入。评价函数和损失函数相似，只不过评价函数的结果不会用于训练过程中。</li></ol><p><pre><code># fit the model
model.fit(training_set, validation_data&#x3D;test_set, epochs&#x3D;epochs, callbacks&#x3D;callbacks, verbose&#x3D;2)</code></pre></p><p>这里的 fit 起到将训练集和测试集载入模型的作用。但是还有另外一个 fit_generator 函数，作用相似。首先 Keras 中的 fit () 函数传入的 x_train 和 y_train 是被完整的加载进内存的，当然用起来很方便，但是如果我们数据量很大，那么是不可能将所有数据载入内存的，必将导致内存泄漏，这时候我们可以用 fit_generator 函数来进行训练。<br><span class="exturl" data-url="aHR0cHM6Ly93d3cudzNjc2Nob29sLmNuL2FydGljbGUvNjI3NTc4MzkuaHRtbCM6fjp0ZXh0PSVFOSVBNiU5NiVFNSU4NSU4OEtlcmFzJUU0JUI4JUFEJUU3JTlBJTg0Zml0LCUyOCUyOSVFNSU4NyVCRCVFNiU5NSVCMCVFNCVCQyVBMCVFNSU4NSVBNSVFNyU5QSU4NHhfdHJhaW4lRTUlOTIlOEN5X3RyYWluJUU2JTk4JUFGJUU4JUEyJUFCJUU1JUFFJThDJUU2JTk1JUI0JUU3JTlBJTg0JUU1JThBJUEwJUU4JUJEJUJEJUU4JUJGJTlCJUU1JTg2JTg1JUU1JUFEJTk4JUU3JTlBJTg0JTJDJUU1JUJEJTkzJUU3JTg0JUI2JUU3JTk0JUE4JUU4JUI1JUI3JUU2JTlEJUE1JUU1JUJFJTg4JUU2JTk2JUI5JUU0JUJFJUJGJUVGJUJDJThDJUU0JUJEJTg2JUU2JTk4JUFGJUU1JUE2JTgyJUU2JTlFJTlDJUU2JTg4JTkxJUU0JUJCJUFDJUU2JTk1JUIwJUU2JThEJUFFJUU5JTg3JThGJUU1JUJFJTg4JUU1JUE0JUE3JUVGJUJDJThDJUU5JTgyJUEzJUU0JUI5JTg4JUU2JTk4JUFGJUU0JUI4JThEJUU1JThGJUFGJUU4JTgzJUJEJUU1JUIwJTg2JUU2JTg5JTgwJUU2JTlDJTg5JUU2JTk1JUIwJUU2JThEJUFFJUU4JUJEJUJEJUU1JTg1JUE1JUU1JTg2JTg1JUU1JUFEJTk4JUU3JTlBJTg0JUVGJUJDJThDJUU1JUJGJTg1JUU1JUIwJTg2JUU1JUFGJUJDJUU4JTg3JUI0JUU1JTg2JTg1JUU1JUFEJTk4JUU2JUIzJTg0JUU2JUJDJThGJUVGJUJDJThDJUU4JUJGJTk5JUU2JTk3JUI2JUU1JTgwJTk5JUU2JTg4JTkxJUU0JUJCJUFDJUU1JThGJUFGJUU0JUJCJUE1JUU3JTk0JUE4Zml0X2dlbmVyYXRvciVFNSU4NyVCRCVFNiU5NSVCMCVFNiU5RCVBNSVFOCVCRiU5QiVFOCVBMSU4QyVFOCVBRSVBRCVFNyVCQiU4MyVFMyU4MCU4Mg==">参考</span>其中有一个常见的参数 verbose--&gt;<em>verbose: 默认值为 1，是指在训练过程中日志的显示模式，取 1 时表示 “进度条模式”，取 2 时表示 “每轮一行”，取 0 时表示 “安静模式”</em></p><h1 id="visualize-the-predicted-images"><a class="anchor" href="#visualize-the-predicted-images">#</a> Visualize the predicted images</h1><p><pre><code># visualize the predicted data
loaded_model &#x3D; keras.models.load_model(&#39;checkpoints&#x2F;model_at_50.h5&#39;)

plt.figure(figsize&#x3D;(15, 9))

def predict(imgs):
    pred &#x3D; []
    for i in loaded_model.predict(images.numpy().astype(&#39;uint8&#39;)):
        if i[0] &gt; .5:
            pred.append(1)
        else:
            pred.append(0)
    return pred
    
for images, labels in test_set.take(1):
    pred &#x3D; predict(images)
    for i in range(12):
        plt.subplot(3, 4, i+1)
        plt.imshow(images[i].numpy().astype(&#39;uint8&#39;))
        plt.title(f&#39;True: {int(labels[i])}, Predicted: {pred[i]}&#39;)
        plt.axis(&#39;off&#39;)</code></pre></p><div class="tags"><a href="/tags/deep-learning/" rel="tag"><i class="ic i-tag"></i> deep learning</a> <a href="/tags/cnn/" rel="tag"><i class="ic i-tag"></i> cnn</a> <a href="/tags/match/" rel="tag"><i class="ic i-tag"></i> match</a> <a href="/tags/image-classification/" rel="tag"><i class="ic i-tag"></i> image classification</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2023-08-06 14:59:49" itemprop="dateModified" datetime="2023-08-06T14:59:49+08:00">2023-08-06</time></span></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>Percy Everard <i class="ic i-at"><em>@</em></i>fengyepiaosa</li><li class="link"><strong>本文链接：</strong> <a href="https://percyeverard.github.io/2022/11/24/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E4%B9%8BCNN%E5%88%86%E7%B1%BB/" title="猫狗大战之 CNN 分类">https://percyeverard.github.io/2022/11/24/猫狗大战之CNN分类/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2022/11/24/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E5%AD%A6%E4%B9%A0%E4%B8%80/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2023&#x2F;08&#x2F;06&#x2F;iN1TzaZOEDywCpu.jpg" title="卷积神经网络CNN学习一"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 知识大陆</span><h3>卷积神经网络CNN学习一</h3></a></div><div class="item right"><a href="/2022/11/26/last-summer-whisper/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2023&#x2F;08&#x2F;06&#x2F;dBMYzbDkO1yoejE.jpg" title="Last summer whisper-杏里"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 金曲共赏</span><h3>Last summer whisper-杏里</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#import-required-libraries-dependencies"><span class="toc-number">1.</span> <span class="toc-text">Import required libraries &#x2F; dependencies</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#generate-the-datasets-both-the-training-and-the-test-sets"><span class="toc-number">2.</span> <span class="toc-text">Generate the datasets, both the training and the test sets</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#define-the-paths-to-the-dataset"><span class="toc-number">2.1.</span> <span class="toc-text">define the paths to the dataset.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#create-dataset"><span class="toc-number">2.2.</span> <span class="toc-text">Create dataset</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#visualize-some-images-from-the-training-set"><span class="toc-number">3.</span> <span class="toc-text">Visualize some images from the training set</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#visualize-the-training-set"><span class="toc-number">3.1.</span> <span class="toc-text">visualize the training set</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#visualize-the-test-set"><span class="toc-number">3.2.</span> <span class="toc-text">visualize the test set</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#data-augmentation"><span class="toc-number">4.</span> <span class="toc-text">Data Augmentation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#define-some-layers-of-data-augmentation"><span class="toc-number">4.1.</span> <span class="toc-text">define some layers of data augmentation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#visualize-it"><span class="toc-number">4.2.</span> <span class="toc-text">visualize it</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#build-a-model"><span class="toc-number">5.</span> <span class="toc-text">Build a model</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#build-the-model"><span class="toc-number">5.1.</span> <span class="toc-text">build the model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-summary"><span class="toc-number">5.2.</span> <span class="toc-text">model summary</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#train-the-model"><span class="toc-number">6.</span> <span class="toc-text">Train the model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#visualize-the-predicted-images"><span class="toc-number">7.</span> <span class="toc-text">Visualize the predicted images</span></a></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2022/11/20/github%E6%96%87%E4%BB%B6%E5%A4%B9%E6%9C%89%E7%99%BD%E8%89%B2%E7%AE%AD%E5%A4%B4%E5%B9%B6%E4%B8%94%E4%B8%8D%E8%83%BD%E6%89%93%E5%BC%80%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/" rel="bookmark" title="github文件夹有白色箭头并且不能打开的解决办法">github文件夹有白色箭头并且不能打开的解决办法</a></li><li><a href="/2022/11/23/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B%E6%89%87%E5%BD%A2%E4%B8%8E%E7%9F%A9%E5%BD%A2%E5%9B%BE%E5%83%8F%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2/" rel="bookmark" title="图像处理之扇形与矩形图像之间的相互转换">图像处理之扇形与矩形图像之间的相互转换</a></li><li><a href="/2022/11/23/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" rel="bookmark" title="激活函数">激活函数</a></li><li><a href="/2022/11/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E9%AA%8C%E4%BA%8C/" rel="bookmark" title="机器学习实验二">机器学习实验二</a></li><li><a href="/2022/11/23/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/" rel="bookmark" title="维度灾难">维度灾难</a></li><li><a href="/2022/11/23/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="bookmark" title="特征工程">特征工程</a></li><li><a href="/2022/11/23/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/" rel="bookmark" title="交叉验证">交叉验证</a></li><li><a href="/2022/11/23/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E8%A1%A5%E5%85%85/" rel="bookmark" title="交叉验证补充">交叉验证补充</a></li><li><a href="/2022/11/23/Jupyter-Notebook/" rel="bookmark" title="Jupyter Notebook">Jupyter Notebook</a></li><li><a href="/2022/11/23/%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE/" rel="bookmark" title="特征缩放">特征缩放</a></li><li><a href="/2022/11/23/L1%E5%92%8CL2%E6%AD%A3%E5%88%99%E5%8C%96/" rel="bookmark" title="L1和L2正则化">L1和L2正则化</a></li><li><a href="/2022/11/23/%E5%9C%A8hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/" rel="bookmark" title="在hexo搭建博客遇到的问题">在hexo搭建博客遇到的问题</a></li><li><a href="/2022/11/23/%E6%8F%92%E5%85%A5YouTube%E8%A7%86%E9%A2%91/" rel="bookmark" title="插入YouTube视频">插入YouTube视频</a></li><li><a href="/2022/11/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B4%BE%E7%B3%BB/" rel="bookmark" title="机器学习派系">机器学习派系</a></li><li><a href="/2022/11/24/%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2/" rel="bookmark" title="网格搜索">网格搜索</a></li><li><a href="/2022/11/24/pip%E5%AE%89%E8%A3%85%E6%96%B0%E5%BA%93/" rel="bookmark" title="pip安装新库">pip安装新库</a></li><li><a href="/2022/11/24/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E5%AD%A6%E4%B9%A0%E4%B8%80/" rel="bookmark" title="卷积神经网络CNN学习一">卷积神经网络CNN学习一</a></li><li class="active"><a href="/2022/11/24/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E4%B9%8BCNN%E5%88%86%E7%B1%BB/" rel="bookmark" title="猫狗大战之CNN分类">猫狗大战之CNN分类</a></li><li><a href="/2022/12/11/docker%E6%89%93%E5%BC%80%E6%8A%A5%E9%94%99/" rel="bookmark" title="docker打开报错">docker打开报错</a></li><li><a href="/2022/12/13/%E5%85%B3%E4%BA%8E%E9%82%A3%E4%BA%9B%E6%88%91%E4%B8%80%E7%9B%B4%E6%90%9E%E4%B8%8D%E6%87%82%E7%9A%84%E5%B8%82%E5%88%B6%E5%8D%95%E4%BD%8D/" rel="bookmark" title="关于那些我一直搞不懂的市制单位">关于那些我一直搞不懂的市制单位</a></li><li><a href="/2023/01/13/TPU%E5%92%8CGPU%E7%9A%84%E4%B8%8D%E5%90%8C%E4%B9%8B%E5%A4%84/" rel="bookmark" title="The difference between GPU AND TPU">The difference between GPU AND TPU</a></li><li><a href="/2023/03/10/Ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85Git/" rel="bookmark" title="Ubuntu下安装Git">Ubuntu下安装Git</a></li><li><a href="/2023/03/11/%E5%88%86%E6%9E%90%E5%BC%80%E6%BA%90MusicPlayer%E7%9A%84%E4%B8%80%E4%BA%9B%E6%94%B6%E8%8E%B7/" rel="bookmark" title="分析开源MusicPlayer的一些收获">分析开源MusicPlayer的一些收获</a></li><li><a href="/2023/03/12/Qt-class-FAQ/" rel="bookmark" title="Qt class FAQ">Qt class FAQ</a></li><li><a href="/2023/03/12/Ubuntu-practise-C-inward/" rel="bookmark" title="Ubuntu practise C++ inward">Ubuntu practise C++ inward</a></li><li><a href="/2023/03/13/%E7%94%A8Qt-Designer%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E5%BA%94%E7%94%A8%E7%9A%84%E6%AD%A5%E9%AA%A4/" rel="bookmark" title="用Qt-Designer设计一个应用的步骤">用Qt-Designer设计一个应用的步骤</a></li><li><a href="/2023/03/13/Qt-Designer%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/" rel="bookmark" title="Qt-Designer常见操作">Qt-Designer常见操作</a></li><li><a href="/2023/03/22/Qt%E6%8E%A7%E4%BB%B6%E5%AD%A6%E4%B9%A02/" rel="bookmark" title="Qt控件学习2">Qt控件学习2</a></li><li><a href="/2023/03/23/libGL/" rel="bookmark" title="Linux环境下Qt报错libGL">Linux环境下Qt报错libGL</a></li><li><a href="/2023/03/28/Qt%E6%8E%A7%E4%BB%B6%E5%AD%A6%E4%B9%A03/" rel="bookmark" title="Qt控件学习3">Qt控件学习3</a></li><li><a href="/2023/04/05/obsidian%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7-%E5%90%AB%E9%93%BE%E6%8E%A5/" rel="bookmark" title="obsidian双向链接">obsidian双向链接</a></li><li><a href="/2023/04/23/xlog-%E5%9B%BE%E5%BA%8A/" rel="bookmark" title="xlog/图床">xlog/图床</a></li><li><a href="/2023/04/30/Linux-%E4%B8%AD%E7%9A%84-32-%E4%BD%8D%E4%B8%8E-64-%E4%BD%8D%E5%8C%BA%E5%88%AB/" rel="bookmark" title="Linux中32位与64位区别">Linux中32位与64位区别</a></li><li><a href="/2023/05/22/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" rel="bookmark" title="视频理解的基础知识">视频理解的基础知识</a></li><li><a href="/2023/07/20/Linux%E7%B3%BB%E7%BB%9F%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/" rel="bookmark" title="Linux系统目录结构">Linux系统目录结构</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Percy Everard" data-src="/images/magic.png"><p class="name" itemprop="name">Percy Everard</p><div class="description" itemprop="description">Really start to record my life, no longer lazy!</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">69</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">7</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">54</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3BlcmN5ZXZlcmFyZA==" title="https:&#x2F;&#x2F;github.com&#x2F;percyeverard"><i class="ic i-github"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvbXkvbS9tdXNpYy9wbGF5bGlzdD9pZD0yMjk0OTY3NTIy" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;my&#x2F;m&#x2F;music&#x2F;playlist?id&#x3D;2294967522"><i class="ic i-cloud-music"></i></span> <span class="exturl item email" data-url="bWFpbHRvOmZlbmd5ZXBpYW9zYUAxNjMuY29t" title="mailto:fengyepiaosa@163.com"><i class="ic i-envelope"></i></span> <span class="exturl item instagram" data-url="aHR0cHM6Ly9pbnN0YWdyYW0uY29tL2NoYXJsZXNmZW5n" title="https:&#x2F;&#x2F;instagram.com&#x2F;charlesfeng"><i class="ic i-instagram"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2022/11/24/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E5%AD%A6%E4%B9%A0%E4%B8%80/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2022/11/26/last-summer-whisper/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"></div><div class="status"><div class="copyright">&copy; 2021 – <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="ic i-wenfeng"></i> </span><span class="author" itemprop="copyrightHolder">Percy Everard @ Percy Feng</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">156k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">2:21</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2022/11/24/猫狗大战之CNN分类/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->